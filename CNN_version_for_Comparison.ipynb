{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\FahadKamran\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\FahadKamran\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\FahadKamran\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\FahadKamran\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:From C:\\Users\\FahadKamran\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\FahadKamran\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "82/82 [==============================] - ETA: 0s - loss: 47.4144 - accuracy: 0.5938\n",
      "Epoch 1: val_accuracy improved from -inf to 0.00399, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FahadKamran\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 133s 2s/step - loss: 47.4144 - accuracy: 0.5938 - val_loss: 0.7161 - val_accuracy: 0.0040\n",
      "Epoch 2/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.7009 - accuracy: 0.6160\n",
      "Epoch 2: val_accuracy improved from 0.00399 to 0.04253, saving model to best_model.h5\n",
      "82/82 [==============================] - 127s 2s/step - loss: 0.7009 - accuracy: 0.6160 - val_loss: 0.7416 - val_accuracy: 0.0425\n",
      "Epoch 3/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.6854 - accuracy: 0.6214\n",
      "Epoch 3: val_accuracy did not improve from 0.04253\n",
      "82/82 [==============================] - 125s 2s/step - loss: 0.6854 - accuracy: 0.6214 - val_loss: 0.7612 - val_accuracy: 0.0128\n",
      "Epoch 4/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.6745 - accuracy: 0.6242\n",
      "Epoch 4: val_accuracy did not improve from 0.04253\n",
      "82/82 [==============================] - 129s 2s/step - loss: 0.6745 - accuracy: 0.6242 - val_loss: 0.7885 - val_accuracy: 0.0235\n",
      "Epoch 5/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.6690 - accuracy: 0.6257\n",
      "Epoch 5: val_accuracy did not improve from 0.04253\n",
      "82/82 [==============================] - 124s 2s/step - loss: 0.6690 - accuracy: 0.6257 - val_loss: 0.8108 - val_accuracy: 0.0372\n",
      "Epoch 6/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.6630 - accuracy: 0.6304\n",
      "Epoch 6: val_accuracy did not improve from 0.04253\n",
      "82/82 [==============================] - 124s 2s/step - loss: 0.6630 - accuracy: 0.6304 - val_loss: 0.8382 - val_accuracy: 0.0359\n",
      "Epoch 7/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.6575 - accuracy: 0.6349\n",
      "Epoch 7: val_accuracy improved from 0.04253 to 0.06026, saving model to best_model.h5\n",
      "82/82 [==============================] - 123s 2s/step - loss: 0.6575 - accuracy: 0.6349 - val_loss: 0.8558 - val_accuracy: 0.0603\n",
      "Epoch 8/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.6472 - accuracy: 0.6436\n",
      "Epoch 8: val_accuracy did not improve from 0.06026\n",
      "82/82 [==============================] - 123s 2s/step - loss: 0.6472 - accuracy: 0.6436 - val_loss: 0.8813 - val_accuracy: 0.0408\n",
      "Epoch 9/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.6398 - accuracy: 0.6449\n",
      "Epoch 9: val_accuracy did not improve from 0.06026\n",
      "82/82 [==============================] - 126s 2s/step - loss: 0.6398 - accuracy: 0.6449 - val_loss: 0.8962 - val_accuracy: 0.0306\n",
      "Epoch 10/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.6388 - accuracy: 0.6415\n",
      "Epoch 10: val_accuracy did not improve from 0.06026\n",
      "82/82 [==============================] - 123s 1s/step - loss: 0.6388 - accuracy: 0.6415 - val_loss: 0.9568 - val_accuracy: 0.0549\n",
      "Epoch 11/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.6132 - accuracy: 0.6539\n",
      "Epoch 11: val_accuracy improved from 0.06026 to 0.07089, saving model to best_model.h5\n",
      "82/82 [==============================] - 124s 2s/step - loss: 0.6132 - accuracy: 0.6539 - val_loss: 0.9223 - val_accuracy: 0.0709\n",
      "Epoch 12/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.5982 - accuracy: 0.6685\n",
      "Epoch 12: val_accuracy improved from 0.07089 to 0.11918, saving model to best_model.h5\n",
      "82/82 [==============================] - 123s 1s/step - loss: 0.5982 - accuracy: 0.6685 - val_loss: 0.8726 - val_accuracy: 0.1192\n",
      "Epoch 13/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.5890 - accuracy: 0.6747\n",
      "Epoch 13: val_accuracy did not improve from 0.11918\n",
      "82/82 [==============================] - 123s 2s/step - loss: 0.5890 - accuracy: 0.6747 - val_loss: 0.8848 - val_accuracy: 0.1086\n",
      "Epoch 14/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.5739 - accuracy: 0.6856\n",
      "Epoch 14: val_accuracy did not improve from 0.11918\n",
      "82/82 [==============================] - 123s 2s/step - loss: 0.5739 - accuracy: 0.6856 - val_loss: 0.9228 - val_accuracy: 0.0992\n",
      "Epoch 15/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.5678 - accuracy: 0.6867\n",
      "Epoch 15: val_accuracy improved from 0.11918 to 0.14976, saving model to best_model.h5\n",
      "82/82 [==============================] - 123s 1s/step - loss: 0.5678 - accuracy: 0.6867 - val_loss: 0.8268 - val_accuracy: 0.1498\n",
      "Epoch 16/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.5613 - accuracy: 0.6872\n",
      "Epoch 16: val_accuracy improved from 0.14976 to 0.16438, saving model to best_model.h5\n",
      "82/82 [==============================] - 123s 1s/step - loss: 0.5613 - accuracy: 0.6872 - val_loss: 0.8585 - val_accuracy: 0.1644\n",
      "Epoch 17/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.5562 - accuracy: 0.6932\n",
      "Epoch 17: val_accuracy improved from 0.16438 to 0.23305, saving model to best_model.h5\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.5562 - accuracy: 0.6932 - val_loss: 0.7757 - val_accuracy: 0.2331\n",
      "Epoch 18/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.5439 - accuracy: 0.6987\n",
      "Epoch 18: val_accuracy did not improve from 0.23305\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.5439 - accuracy: 0.6987 - val_loss: 0.8300 - val_accuracy: 0.1537\n",
      "Epoch 19/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.5375 - accuracy: 0.6984\n",
      "Epoch 19: val_accuracy improved from 0.23305 to 0.29508, saving model to best_model.h5\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.5375 - accuracy: 0.6984 - val_loss: 0.7286 - val_accuracy: 0.2951\n",
      "Epoch 20/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.5269 - accuracy: 0.7047\n",
      "Epoch 20: val_accuracy improved from 0.29508 to 0.33451, saving model to best_model.h5\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.5269 - accuracy: 0.7047 - val_loss: 0.7053 - val_accuracy: 0.3345\n",
      "Epoch 21/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.5282 - accuracy: 0.7029\n",
      "Epoch 21: val_accuracy did not improve from 0.33451\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.5282 - accuracy: 0.7029 - val_loss: 0.8306 - val_accuracy: 0.1887\n",
      "Epoch 22/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.5271 - accuracy: 0.7014\n",
      "Epoch 22: val_accuracy did not improve from 0.33451\n",
      "82/82 [==============================] - 123s 2s/step - loss: 0.5271 - accuracy: 0.7014 - val_loss: 0.8118 - val_accuracy: 0.2189\n",
      "Epoch 23/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.5108 - accuracy: 0.7081\n",
      "Epoch 23: val_accuracy did not improve from 0.33451\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.5108 - accuracy: 0.7081 - val_loss: 0.7697 - val_accuracy: 0.2827\n",
      "Epoch 24/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.5071 - accuracy: 0.7094\n",
      "Epoch 24: val_accuracy did not improve from 0.33451\n",
      "82/82 [==============================] - 123s 1s/step - loss: 0.5071 - accuracy: 0.7094 - val_loss: 0.8382 - val_accuracy: 0.2335\n",
      "Epoch 25/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.5034 - accuracy: 0.7069\n",
      "Epoch 25: val_accuracy did not improve from 0.33451\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.5034 - accuracy: 0.7069 - val_loss: 0.7701 - val_accuracy: 0.3124\n",
      "Epoch 26/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.5046 - accuracy: 0.7072\n",
      "Epoch 26: val_accuracy improved from 0.33451 to 0.35800, saving model to best_model.h5\n",
      "82/82 [==============================] - 125s 2s/step - loss: 0.5046 - accuracy: 0.7072 - val_loss: 0.7581 - val_accuracy: 0.3580\n",
      "Epoch 27/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4960 - accuracy: 0.7106\n",
      "Epoch 27: val_accuracy did not improve from 0.35800\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.4960 - accuracy: 0.7106 - val_loss: 0.8192 - val_accuracy: 0.3460\n",
      "Epoch 28/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.5041 - accuracy: 0.7045\n",
      "Epoch 28: val_accuracy did not improve from 0.35800\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.5041 - accuracy: 0.7045 - val_loss: 0.8710 - val_accuracy: 0.2561\n",
      "Epoch 29/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.5035 - accuracy: 0.7057\n",
      "Epoch 29: val_accuracy improved from 0.35800 to 0.46123, saving model to best_model.h5\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.5035 - accuracy: 0.7057 - val_loss: 0.7347 - val_accuracy: 0.4612\n",
      "Epoch 30/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4859 - accuracy: 0.7088\n",
      "Epoch 30: val_accuracy did not improve from 0.46123\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.4859 - accuracy: 0.7088 - val_loss: 0.7703 - val_accuracy: 0.3332\n",
      "Epoch 31/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4838 - accuracy: 0.7104\n",
      "Epoch 31: val_accuracy did not improve from 0.46123\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.4838 - accuracy: 0.7104 - val_loss: 0.7234 - val_accuracy: 0.4502\n",
      "Epoch 32/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4823 - accuracy: 0.7128\n",
      "Epoch 32: val_accuracy improved from 0.46123 to 0.46300, saving model to best_model.h5\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.4823 - accuracy: 0.7128 - val_loss: 0.7133 - val_accuracy: 0.4630\n",
      "Epoch 33/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4736 - accuracy: 0.7177\n",
      "Epoch 33: val_accuracy improved from 0.46300 to 0.47054, saving model to best_model.h5\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.4736 - accuracy: 0.7177 - val_loss: 0.7443 - val_accuracy: 0.4705\n",
      "Epoch 34/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4741 - accuracy: 0.7120\n",
      "Epoch 34: val_accuracy did not improve from 0.47054\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.4741 - accuracy: 0.7120 - val_loss: 0.7535 - val_accuracy: 0.4373\n",
      "Epoch 35/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4695 - accuracy: 0.7172\n",
      "Epoch 35: val_accuracy did not improve from 0.47054\n",
      "82/82 [==============================] - 121s 1s/step - loss: 0.4695 - accuracy: 0.7172 - val_loss: 0.8159 - val_accuracy: 0.3890\n",
      "Epoch 36/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4636 - accuracy: 0.7187\n",
      "Epoch 36: val_accuracy did not improve from 0.47054\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.4636 - accuracy: 0.7187 - val_loss: 0.8464 - val_accuracy: 0.3983\n",
      "Epoch 37/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4607 - accuracy: 0.7320\n",
      "Epoch 37: val_accuracy improved from 0.47054 to 0.64909, saving model to best_model.h5\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.4607 - accuracy: 0.7320 - val_loss: 0.7664 - val_accuracy: 0.6491\n",
      "Epoch 38/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4597 - accuracy: 0.7492\n",
      "Epoch 38: val_accuracy improved from 0.64909 to 0.68276, saving model to best_model.h5\n",
      "82/82 [==============================] - 123s 1s/step - loss: 0.4597 - accuracy: 0.7492 - val_loss: 0.7136 - val_accuracy: 0.6828\n",
      "Epoch 39/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4553 - accuracy: 0.7516\n",
      "Epoch 39: val_accuracy did not improve from 0.68276\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.4553 - accuracy: 0.7516 - val_loss: 0.7853 - val_accuracy: 0.6650\n",
      "Epoch 40/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4435 - accuracy: 0.7592\n",
      "Epoch 40: val_accuracy improved from 0.68276 to 0.69163, saving model to best_model.h5\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.4435 - accuracy: 0.7592 - val_loss: 0.7814 - val_accuracy: 0.6916\n",
      "Epoch 41/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4505 - accuracy: 0.7571\n",
      "Epoch 41: val_accuracy did not improve from 0.69163\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.4505 - accuracy: 0.7571 - val_loss: 0.8354 - val_accuracy: 0.6269\n",
      "Epoch 42/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4524 - accuracy: 0.7590\n",
      "Epoch 42: val_accuracy improved from 0.69163 to 0.70846, saving model to best_model.h5\n",
      "82/82 [==============================] - 123s 1s/step - loss: 0.4524 - accuracy: 0.7590 - val_loss: 0.7656 - val_accuracy: 0.7085\n",
      "Epoch 43/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4382 - accuracy: 0.7632\n",
      "Epoch 43: val_accuracy did not improve from 0.70846\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.4382 - accuracy: 0.7632 - val_loss: 0.8785 - val_accuracy: 0.6238\n",
      "Epoch 44/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4503 - accuracy: 0.7615\n",
      "Epoch 44: val_accuracy improved from 0.70846 to 0.71599, saving model to best_model.h5\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.4503 - accuracy: 0.7615 - val_loss: 0.7138 - val_accuracy: 0.7160\n",
      "Epoch 45/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4501 - accuracy: 0.7528\n",
      "Epoch 45: val_accuracy did not improve from 0.71599\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.4501 - accuracy: 0.7528 - val_loss: 0.8839 - val_accuracy: 0.6309\n",
      "Epoch 46/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4452 - accuracy: 0.7604\n",
      "Epoch 46: val_accuracy did not improve from 0.71599\n",
      "82/82 [==============================] - 121s 1s/step - loss: 0.4452 - accuracy: 0.7604 - val_loss: 0.8013 - val_accuracy: 0.6783\n",
      "Epoch 47/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4341 - accuracy: 0.7601\n",
      "Epoch 47: val_accuracy did not improve from 0.71599\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.4341 - accuracy: 0.7601 - val_loss: 0.7809 - val_accuracy: 0.6956\n",
      "Epoch 48/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4346 - accuracy: 0.7666\n",
      "Epoch 48: val_accuracy did not improve from 0.71599\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.4346 - accuracy: 0.7666 - val_loss: 0.9054 - val_accuracy: 0.6584\n",
      "Epoch 49/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4387 - accuracy: 0.7678\n",
      "Epoch 49: val_accuracy improved from 0.71599 to 0.78689, saving model to best_model.h5\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.4387 - accuracy: 0.7678 - val_loss: 0.7186 - val_accuracy: 0.7869\n",
      "Epoch 50/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4564 - accuracy: 0.7504\n",
      "Epoch 50: val_accuracy did not improve from 0.78689\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.4564 - accuracy: 0.7504 - val_loss: 0.7445 - val_accuracy: 0.7435\n",
      "Epoch 51/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4358 - accuracy: 0.7715\n",
      "Epoch 51: val_accuracy did not improve from 0.78689\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.4358 - accuracy: 0.7715 - val_loss: 0.7085 - val_accuracy: 0.7700\n",
      "Epoch 52/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4349 - accuracy: 0.7705\n",
      "Epoch 52: val_accuracy did not improve from 0.78689\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.4349 - accuracy: 0.7705 - val_loss: 0.7462 - val_accuracy: 0.7399\n",
      "Epoch 53/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4219 - accuracy: 0.7733\n",
      "Epoch 53: val_accuracy did not improve from 0.78689\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.4219 - accuracy: 0.7733 - val_loss: 0.7267 - val_accuracy: 0.7599\n",
      "Epoch 54/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4108 - accuracy: 0.7778\n",
      "Epoch 54: val_accuracy did not improve from 0.78689\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.4108 - accuracy: 0.7778 - val_loss: 0.7294 - val_accuracy: 0.7421\n",
      "Epoch 55/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4075 - accuracy: 0.7806\n",
      "Epoch 55: val_accuracy did not improve from 0.78689\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.4075 - accuracy: 0.7806 - val_loss: 0.7042 - val_accuracy: 0.7674\n",
      "Epoch 56/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4010 - accuracy: 0.7853\n",
      "Epoch 56: val_accuracy did not improve from 0.78689\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.4010 - accuracy: 0.7853 - val_loss: 0.7407 - val_accuracy: 0.7523\n",
      "Epoch 57/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4101 - accuracy: 0.7791\n",
      "Epoch 57: val_accuracy did not improve from 0.78689\n",
      "82/82 [==============================] - 123s 1s/step - loss: 0.4101 - accuracy: 0.7791 - val_loss: 0.7817 - val_accuracy: 0.7067\n",
      "Epoch 58/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3933 - accuracy: 0.7864\n",
      "Epoch 58: val_accuracy did not improve from 0.78689\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.3933 - accuracy: 0.7864 - val_loss: 0.7128 - val_accuracy: 0.7572\n",
      "Epoch 59/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3928 - accuracy: 0.7896\n",
      "Epoch 59: val_accuracy did not improve from 0.78689\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.3928 - accuracy: 0.7896 - val_loss: 0.9307 - val_accuracy: 0.6340\n",
      "Epoch 60/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3803 - accuracy: 0.7963\n",
      "Epoch 60: val_accuracy did not improve from 0.78689\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.3803 - accuracy: 0.7963 - val_loss: 0.9580 - val_accuracy: 0.6588\n",
      "Epoch 61/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3846 - accuracy: 0.7981\n",
      "Epoch 61: val_accuracy did not improve from 0.78689\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.3846 - accuracy: 0.7981 - val_loss: 0.8389 - val_accuracy: 0.7151\n",
      "Epoch 62/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3733 - accuracy: 0.8028\n",
      "Epoch 62: val_accuracy did not improve from 0.78689\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.3733 - accuracy: 0.8028 - val_loss: 1.0731 - val_accuracy: 0.6238\n",
      "Epoch 63/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3771 - accuracy: 0.8022\n",
      "Epoch 63: val_accuracy did not improve from 0.78689\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.3771 - accuracy: 0.8022 - val_loss: 0.8334 - val_accuracy: 0.7271\n",
      "Epoch 64/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3802 - accuracy: 0.7982\n",
      "Epoch 64: val_accuracy did not improve from 0.78689\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.3802 - accuracy: 0.7982 - val_loss: 0.7210 - val_accuracy: 0.7652\n",
      "Epoch 65/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3931 - accuracy: 0.7908\n",
      "Epoch 65: val_accuracy did not improve from 0.78689\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.3931 - accuracy: 0.7908 - val_loss: 0.8526 - val_accuracy: 0.6947\n",
      "Epoch 66/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3738 - accuracy: 0.8010\n",
      "Epoch 66: val_accuracy did not improve from 0.78689\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.3738 - accuracy: 0.8010 - val_loss: 0.8507 - val_accuracy: 0.7009\n",
      "Epoch 67/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3570 - accuracy: 0.8094\n",
      "Epoch 67: val_accuracy did not improve from 0.78689\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.3570 - accuracy: 0.8094 - val_loss: 0.7729 - val_accuracy: 0.7147\n",
      "Epoch 68/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3590 - accuracy: 0.8135\n",
      "Epoch 68: val_accuracy did not improve from 0.78689\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.3590 - accuracy: 0.8135 - val_loss: 0.7382 - val_accuracy: 0.7399\n",
      "Epoch 69/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3438 - accuracy: 0.8228\n",
      "Epoch 69: val_accuracy did not improve from 0.78689\n",
      "82/82 [==============================] - 121s 1s/step - loss: 0.3438 - accuracy: 0.8228 - val_loss: 0.7275 - val_accuracy: 0.7820\n",
      "Epoch 70/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3526 - accuracy: 0.8186\n",
      "Epoch 70: val_accuracy did not improve from 0.78689\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.3526 - accuracy: 0.8186 - val_loss: 0.7200 - val_accuracy: 0.7625\n",
      "Epoch 71/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3460 - accuracy: 0.8212\n",
      "Epoch 71: val_accuracy did not improve from 0.78689\n",
      "82/82 [==============================] - 121s 1s/step - loss: 0.3460 - accuracy: 0.8212 - val_loss: 0.7462 - val_accuracy: 0.7519\n",
      "Epoch 72/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3421 - accuracy: 0.8240\n",
      "Epoch 72: val_accuracy did not improve from 0.78689\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.3421 - accuracy: 0.8240 - val_loss: 0.8693 - val_accuracy: 0.7058\n",
      "Epoch 73/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3404 - accuracy: 0.8263\n",
      "Epoch 73: val_accuracy did not improve from 0.78689\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.3404 - accuracy: 0.8263 - val_loss: 0.9403 - val_accuracy: 0.6779\n",
      "Epoch 74/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3369 - accuracy: 0.8257\n",
      "Epoch 74: val_accuracy did not improve from 0.78689\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.3369 - accuracy: 0.8257 - val_loss: 0.8802 - val_accuracy: 0.7173\n",
      "Epoch 75/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3411 - accuracy: 0.8235\n",
      "Epoch 75: val_accuracy did not improve from 0.78689\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.3411 - accuracy: 0.8235 - val_loss: 0.7606 - val_accuracy: 0.7585\n",
      "Epoch 76/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3312 - accuracy: 0.8313\n",
      "Epoch 76: val_accuracy did not improve from 0.78689\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.3312 - accuracy: 0.8313 - val_loss: 0.7159 - val_accuracy: 0.7683\n",
      "Epoch 77/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3225 - accuracy: 0.8320\n",
      "Epoch 77: val_accuracy did not improve from 0.78689\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.3225 - accuracy: 0.8320 - val_loss: 0.7622 - val_accuracy: 0.7856\n",
      "Epoch 78/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3307 - accuracy: 0.8255\n",
      "Epoch 78: val_accuracy did not improve from 0.78689\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.3307 - accuracy: 0.8255 - val_loss: 0.8023 - val_accuracy: 0.7452\n",
      "Epoch 79/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3228 - accuracy: 0.8349\n",
      "Epoch 79: val_accuracy did not improve from 0.78689\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.3228 - accuracy: 0.8349 - val_loss: 0.9898 - val_accuracy: 0.6743\n",
      "Epoch 80/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3177 - accuracy: 0.8387\n",
      "Epoch 80: val_accuracy did not improve from 0.78689\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.3177 - accuracy: 0.8387 - val_loss: 0.8412 - val_accuracy: 0.7049\n",
      "Epoch 81/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3176 - accuracy: 0.8429\n",
      "Epoch 81: val_accuracy did not improve from 0.78689\n",
      "82/82 [==============================] - 121s 1s/step - loss: 0.3176 - accuracy: 0.8429 - val_loss: 0.9838 - val_accuracy: 0.6814\n",
      "Epoch 82/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3067 - accuracy: 0.8423\n",
      "Epoch 82: val_accuracy improved from 0.78689 to 0.79442, saving model to best_model.h5\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.3067 - accuracy: 0.8423 - val_loss: 0.6824 - val_accuracy: 0.7944\n",
      "Epoch 83/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3187 - accuracy: 0.8424\n",
      "Epoch 83: val_accuracy did not improve from 0.79442\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.3187 - accuracy: 0.8424 - val_loss: 0.8545 - val_accuracy: 0.7355\n",
      "Epoch 84/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3038 - accuracy: 0.8484\n",
      "Epoch 84: val_accuracy did not improve from 0.79442\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.3038 - accuracy: 0.8484 - val_loss: 1.0156 - val_accuracy: 0.6788\n",
      "Epoch 85/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3041 - accuracy: 0.8463\n",
      "Epoch 85: val_accuracy did not improve from 0.79442\n",
      "82/82 [==============================] - 121s 1s/step - loss: 0.3041 - accuracy: 0.8463 - val_loss: 0.8907 - val_accuracy: 0.7381\n",
      "Epoch 86/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3008 - accuracy: 0.8480\n",
      "Epoch 86: val_accuracy did not improve from 0.79442\n",
      "82/82 [==============================] - 121s 1s/step - loss: 0.3008 - accuracy: 0.8480 - val_loss: 0.8179 - val_accuracy: 0.7541\n",
      "Epoch 87/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3029 - accuracy: 0.8476\n",
      "Epoch 87: val_accuracy did not improve from 0.79442\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.3029 - accuracy: 0.8476 - val_loss: 1.0677 - val_accuracy: 0.7062\n",
      "Epoch 88/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2874 - accuracy: 0.8554\n",
      "Epoch 88: val_accuracy did not improve from 0.79442\n",
      "82/82 [==============================] - 121s 1s/step - loss: 0.2874 - accuracy: 0.8554 - val_loss: 0.7428 - val_accuracy: 0.7789\n",
      "Epoch 89/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2972 - accuracy: 0.8505\n",
      "Epoch 89: val_accuracy did not improve from 0.79442\n",
      "82/82 [==============================] - 121s 1s/step - loss: 0.2972 - accuracy: 0.8505 - val_loss: 0.8830 - val_accuracy: 0.7235\n",
      "Epoch 90/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2903 - accuracy: 0.8569\n",
      "Epoch 90: val_accuracy did not improve from 0.79442\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.2903 - accuracy: 0.8569 - val_loss: 0.9913 - val_accuracy: 0.7049\n",
      "Epoch 91/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2880 - accuracy: 0.8538\n",
      "Epoch 91: val_accuracy did not improve from 0.79442\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.2880 - accuracy: 0.8538 - val_loss: 0.9872 - val_accuracy: 0.7107\n",
      "Epoch 92/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2889 - accuracy: 0.8541\n",
      "Epoch 92: val_accuracy did not improve from 0.79442\n",
      "82/82 [==============================] - 121s 1s/step - loss: 0.2889 - accuracy: 0.8541 - val_loss: 0.9925 - val_accuracy: 0.7240\n",
      "Epoch 93/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2931 - accuracy: 0.8524\n",
      "Epoch 93: val_accuracy did not improve from 0.79442\n",
      "82/82 [==============================] - 121s 1s/step - loss: 0.2931 - accuracy: 0.8524 - val_loss: 0.9707 - val_accuracy: 0.7337\n",
      "Epoch 94/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2866 - accuracy: 0.8591\n",
      "Epoch 94: val_accuracy did not improve from 0.79442\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.2866 - accuracy: 0.8591 - val_loss: 0.8460 - val_accuracy: 0.7559\n",
      "Epoch 95/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2872 - accuracy: 0.8582\n",
      "Epoch 95: val_accuracy did not improve from 0.79442\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.2872 - accuracy: 0.8582 - val_loss: 1.0682 - val_accuracy: 0.6961\n",
      "Epoch 96/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2992 - accuracy: 0.8522\n",
      "Epoch 96: val_accuracy did not improve from 0.79442\n",
      "82/82 [==============================] - 121s 1s/step - loss: 0.2992 - accuracy: 0.8522 - val_loss: 0.9233 - val_accuracy: 0.7315\n",
      "Epoch 97/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2816 - accuracy: 0.8588\n",
      "Epoch 97: val_accuracy did not improve from 0.79442\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.2816 - accuracy: 0.8588 - val_loss: 0.9848 - val_accuracy: 0.7209\n",
      "Epoch 98/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2685 - accuracy: 0.8677\n",
      "Epoch 98: val_accuracy did not improve from 0.79442\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.2685 - accuracy: 0.8677 - val_loss: 0.9477 - val_accuracy: 0.7399\n",
      "Epoch 99/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2762 - accuracy: 0.8625\n",
      "Epoch 99: val_accuracy did not improve from 0.79442\n",
      "82/82 [==============================] - 123s 1s/step - loss: 0.2762 - accuracy: 0.8625 - val_loss: 1.0008 - val_accuracy: 0.7125\n",
      "Epoch 100/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2697 - accuracy: 0.8667\n",
      "Epoch 100: val_accuracy did not improve from 0.79442\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.2697 - accuracy: 0.8667 - val_loss: 0.9136 - val_accuracy: 0.7226\n",
      "Epoch 101/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2717 - accuracy: 0.8692\n",
      "Epoch 101: val_accuracy did not improve from 0.79442\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.2717 - accuracy: 0.8692 - val_loss: 1.2608 - val_accuracy: 0.6464\n",
      "Epoch 102/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2671 - accuracy: 0.8684\n",
      "Epoch 102: val_accuracy did not improve from 0.79442\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.2671 - accuracy: 0.8684 - val_loss: 0.9205 - val_accuracy: 0.7497\n",
      "Epoch 103/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3635 - accuracy: 0.8191\n",
      "Epoch 103: val_accuracy did not improve from 0.79442\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.3635 - accuracy: 0.8191 - val_loss: 0.8420 - val_accuracy: 0.7674\n",
      "Epoch 104/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2922 - accuracy: 0.8573\n",
      "Epoch 104: val_accuracy did not improve from 0.79442\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.2922 - accuracy: 0.8573 - val_loss: 1.1242 - val_accuracy: 0.6659\n",
      "Epoch 105/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2779 - accuracy: 0.8651\n",
      "Epoch 105: val_accuracy improved from 0.79442 to 0.79530, saving model to best_model.h5\n",
      "82/82 [==============================] - 125s 2s/step - loss: 0.2779 - accuracy: 0.8651 - val_loss: 0.7199 - val_accuracy: 0.7953\n",
      "Epoch 106/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3013 - accuracy: 0.8531\n",
      "Epoch 106: val_accuracy did not improve from 0.79530\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.3013 - accuracy: 0.8531 - val_loss: 0.8812 - val_accuracy: 0.7373\n",
      "Epoch 107/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2723 - accuracy: 0.8679\n",
      "Epoch 107: val_accuracy did not improve from 0.79530\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.2723 - accuracy: 0.8679 - val_loss: 1.0656 - val_accuracy: 0.6956\n",
      "Epoch 108/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2664 - accuracy: 0.8734\n",
      "Epoch 108: val_accuracy did not improve from 0.79530\n",
      "82/82 [==============================] - 123s 1s/step - loss: 0.2664 - accuracy: 0.8734 - val_loss: 0.7845 - val_accuracy: 0.7647\n",
      "Epoch 109/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2718 - accuracy: 0.8683\n",
      "Epoch 109: val_accuracy did not improve from 0.79530\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.2718 - accuracy: 0.8683 - val_loss: 1.0591 - val_accuracy: 0.6872\n",
      "Epoch 110/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2561 - accuracy: 0.8764\n",
      "Epoch 110: val_accuracy did not improve from 0.79530\n",
      "82/82 [==============================] - 123s 1s/step - loss: 0.2561 - accuracy: 0.8764 - val_loss: 1.1468 - val_accuracy: 0.7226\n",
      "Epoch 111/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2723 - accuracy: 0.8693\n",
      "Epoch 111: val_accuracy improved from 0.79530 to 0.84138, saving model to best_model.h5\n",
      "82/82 [==============================] - 124s 2s/step - loss: 0.2723 - accuracy: 0.8693 - val_loss: 0.6003 - val_accuracy: 0.8414\n",
      "Epoch 112/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2916 - accuracy: 0.8565\n",
      "Epoch 112: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 130s 2s/step - loss: 0.2916 - accuracy: 0.8565 - val_loss: 0.9037 - val_accuracy: 0.7364\n",
      "Epoch 113/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2557 - accuracy: 0.8776\n",
      "Epoch 113: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 120s 1s/step - loss: 0.2557 - accuracy: 0.8776 - val_loss: 1.0601 - val_accuracy: 0.6872\n",
      "Epoch 114/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2618 - accuracy: 0.8754\n",
      "Epoch 114: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 115s 1s/step - loss: 0.2618 - accuracy: 0.8754 - val_loss: 0.9608 - val_accuracy: 0.7275\n",
      "Epoch 115/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2470 - accuracy: 0.8832\n",
      "Epoch 115: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 113s 1s/step - loss: 0.2470 - accuracy: 0.8832 - val_loss: 0.8789 - val_accuracy: 0.7607\n",
      "Epoch 116/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2502 - accuracy: 0.8781\n",
      "Epoch 116: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 113s 1s/step - loss: 0.2502 - accuracy: 0.8781 - val_loss: 1.0656 - val_accuracy: 0.6930\n",
      "Epoch 117/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2487 - accuracy: 0.8808\n",
      "Epoch 117: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 118s 1s/step - loss: 0.2487 - accuracy: 0.8808 - val_loss: 1.0868 - val_accuracy: 0.7107\n",
      "Epoch 118/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2495 - accuracy: 0.8827\n",
      "Epoch 118: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 116s 1s/step - loss: 0.2495 - accuracy: 0.8827 - val_loss: 0.8025 - val_accuracy: 0.7736\n",
      "Epoch 119/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2425 - accuracy: 0.8855\n",
      "Epoch 119: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 121s 1s/step - loss: 0.2425 - accuracy: 0.8855 - val_loss: 1.2933 - val_accuracy: 0.6522\n",
      "Epoch 120/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2467 - accuracy: 0.8835\n",
      "Epoch 120: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 127s 2s/step - loss: 0.2467 - accuracy: 0.8835 - val_loss: 0.7556 - val_accuracy: 0.7842\n",
      "Epoch 121/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2462 - accuracy: 0.8876\n",
      "Epoch 121: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 124s 2s/step - loss: 0.2462 - accuracy: 0.8876 - val_loss: 1.0136 - val_accuracy: 0.7023\n",
      "Epoch 122/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2366 - accuracy: 0.8878\n",
      "Epoch 122: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 126s 2s/step - loss: 0.2366 - accuracy: 0.8878 - val_loss: 1.0368 - val_accuracy: 0.7080\n",
      "Epoch 123/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2400 - accuracy: 0.8866\n",
      "Epoch 123: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 123s 1s/step - loss: 0.2400 - accuracy: 0.8866 - val_loss: 0.8721 - val_accuracy: 0.7519\n",
      "Epoch 124/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2299 - accuracy: 0.8891\n",
      "Epoch 124: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 122s 1s/step - loss: 0.2299 - accuracy: 0.8891 - val_loss: 0.9658 - val_accuracy: 0.7381\n",
      "Epoch 125/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2428 - accuracy: 0.8867\n",
      "Epoch 125: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 126s 2s/step - loss: 0.2428 - accuracy: 0.8867 - val_loss: 0.7766 - val_accuracy: 0.7847\n",
      "Epoch 126/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2360 - accuracy: 0.8906\n",
      "Epoch 126: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 123s 1s/step - loss: 0.2360 - accuracy: 0.8906 - val_loss: 1.0602 - val_accuracy: 0.6819\n",
      "Epoch 127/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2342 - accuracy: 0.8916\n",
      "Epoch 127: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 127s 2s/step - loss: 0.2342 - accuracy: 0.8916 - val_loss: 1.0499 - val_accuracy: 0.7178\n",
      "Epoch 128/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2249 - accuracy: 0.8954\n",
      "Epoch 128: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 123s 2s/step - loss: 0.2249 - accuracy: 0.8954 - val_loss: 1.1138 - val_accuracy: 0.7244\n",
      "Epoch 129/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2278 - accuracy: 0.8922\n",
      "Epoch 129: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 126s 2s/step - loss: 0.2278 - accuracy: 0.8922 - val_loss: 1.2742 - val_accuracy: 0.6876\n",
      "Epoch 130/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2333 - accuracy: 0.8941\n",
      "Epoch 130: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 124s 2s/step - loss: 0.2333 - accuracy: 0.8941 - val_loss: 0.9344 - val_accuracy: 0.7630\n",
      "Epoch 131/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2418 - accuracy: 0.8879\n",
      "Epoch 131: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 124s 2s/step - loss: 0.2418 - accuracy: 0.8879 - val_loss: 0.9447 - val_accuracy: 0.7373\n",
      "Epoch 132/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2393 - accuracy: 0.8924\n",
      "Epoch 132: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 124s 2s/step - loss: 0.2393 - accuracy: 0.8924 - val_loss: 0.7501 - val_accuracy: 0.7776\n",
      "Epoch 133/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2422 - accuracy: 0.8868\n",
      "Epoch 133: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 124s 2s/step - loss: 0.2422 - accuracy: 0.8868 - val_loss: 0.9843 - val_accuracy: 0.7483\n",
      "Epoch 134/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2202 - accuracy: 0.8986\n",
      "Epoch 134: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 124s 2s/step - loss: 0.2202 - accuracy: 0.8986 - val_loss: 0.8544 - val_accuracy: 0.7767\n",
      "Epoch 135/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2229 - accuracy: 0.8973\n",
      "Epoch 135: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 123s 2s/step - loss: 0.2229 - accuracy: 0.8973 - val_loss: 1.2577 - val_accuracy: 0.6850\n",
      "Epoch 136/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2142 - accuracy: 0.9004\n",
      "Epoch 136: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 123s 2s/step - loss: 0.2142 - accuracy: 0.9004 - val_loss: 0.9402 - val_accuracy: 0.7452\n",
      "Epoch 137/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2190 - accuracy: 0.9017\n",
      "Epoch 137: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 123s 2s/step - loss: 0.2190 - accuracy: 0.9017 - val_loss: 1.1981 - val_accuracy: 0.6943\n",
      "Epoch 138/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2079 - accuracy: 0.9048\n",
      "Epoch 138: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 123s 2s/step - loss: 0.2079 - accuracy: 0.9048 - val_loss: 1.0631 - val_accuracy: 0.7359\n",
      "Epoch 139/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2168 - accuracy: 0.9023\n",
      "Epoch 139: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 123s 2s/step - loss: 0.2168 - accuracy: 0.9023 - val_loss: 0.8939 - val_accuracy: 0.7820\n",
      "Epoch 140/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2115 - accuracy: 0.9018\n",
      "Epoch 140: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 123s 2s/step - loss: 0.2115 - accuracy: 0.9018 - val_loss: 0.8758 - val_accuracy: 0.7794\n",
      "Epoch 141/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2156 - accuracy: 0.9011\n",
      "Epoch 141: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 123s 2s/step - loss: 0.2156 - accuracy: 0.9011 - val_loss: 1.1402 - val_accuracy: 0.7209\n",
      "Epoch 142/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2169 - accuracy: 0.9035\n",
      "Epoch 142: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 123s 2s/step - loss: 0.2169 - accuracy: 0.9035 - val_loss: 0.8802 - val_accuracy: 0.7851\n",
      "Epoch 143/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2097 - accuracy: 0.9046\n",
      "Epoch 143: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 123s 2s/step - loss: 0.2097 - accuracy: 0.9046 - val_loss: 1.1685 - val_accuracy: 0.7018\n",
      "Epoch 144/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2063 - accuracy: 0.9089\n",
      "Epoch 144: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 123s 2s/step - loss: 0.2063 - accuracy: 0.9089 - val_loss: 1.0101 - val_accuracy: 0.7359\n",
      "Epoch 145/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2150 - accuracy: 0.9057\n",
      "Epoch 145: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 123s 2s/step - loss: 0.2150 - accuracy: 0.9057 - val_loss: 0.8644 - val_accuracy: 0.7794\n",
      "Epoch 146/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2356 - accuracy: 0.8929\n",
      "Epoch 146: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 123s 2s/step - loss: 0.2356 - accuracy: 0.8929 - val_loss: 0.7631 - val_accuracy: 0.7944\n",
      "Epoch 147/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2219 - accuracy: 0.8988\n",
      "Epoch 147: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 125s 2s/step - loss: 0.2219 - accuracy: 0.8988 - val_loss: 0.9379 - val_accuracy: 0.7661\n",
      "Epoch 148/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2123 - accuracy: 0.9055\n",
      "Epoch 148: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 129s 2s/step - loss: 0.2123 - accuracy: 0.9055 - val_loss: 1.1145 - val_accuracy: 0.7506\n",
      "Epoch 149/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2102 - accuracy: 0.9074\n",
      "Epoch 149: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 130s 2s/step - loss: 0.2102 - accuracy: 0.9074 - val_loss: 0.8981 - val_accuracy: 0.7669\n",
      "Epoch 150/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.1959 - accuracy: 0.9108\n",
      "Epoch 150: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 129s 2s/step - loss: 0.1959 - accuracy: 0.9108 - val_loss: 1.1093 - val_accuracy: 0.7435\n",
      "Epoch 151/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2035 - accuracy: 0.9099\n",
      "Epoch 151: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 131s 2s/step - loss: 0.2035 - accuracy: 0.9099 - val_loss: 1.3231 - val_accuracy: 0.6580\n",
      "Epoch 152/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2147 - accuracy: 0.9027\n",
      "Epoch 152: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 123s 2s/step - loss: 0.2147 - accuracy: 0.9027 - val_loss: 0.8573 - val_accuracy: 0.7683\n",
      "Epoch 153/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2187 - accuracy: 0.9037\n",
      "Epoch 153: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 125s 2s/step - loss: 0.2187 - accuracy: 0.9037 - val_loss: 1.0464 - val_accuracy: 0.7444\n",
      "Epoch 154/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.1971 - accuracy: 0.9139\n",
      "Epoch 154: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 124s 2s/step - loss: 0.1971 - accuracy: 0.9139 - val_loss: 1.2307 - val_accuracy: 0.6992\n",
      "Epoch 155/500\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.1879 - accuracy: 0.9178\n",
      "Epoch 155: val_accuracy did not improve from 0.84138\n",
      "82/82 [==============================] - 124s 2s/step - loss: 0.1879 - accuracy: 0.9178 - val_loss: 1.1714 - val_accuracy: 0.7014\n",
      "Epoch 156/500\n",
      "57/82 [===================>..........] - ETA: 36s - loss: 0.1936 - accuracy: 0.9135"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "# Load and preprocess the data\n",
    "train_data_dir = \"D:/DATASET/DATASET/TRAIN\"\n",
    "test_data_dir = \"D:/DATASET/DATASET/TEST\"\n",
    "image_size = (128, 128)  # Set your desired image size\n",
    "\n",
    "train_data = []  # List to store train image data\n",
    "train_labels = []  # List to store train labels\n",
    "test_data = [] #list to store test image data\n",
    "test_labels = [] # list to store test labels\n",
    "\n",
    "# Define a function to extract the label from the folder name\n",
    "def extract_label(folder_name):\n",
    "    return 0 if folder_name == 'O' else 1\n",
    "\n",
    "# Iterate through subdirectories (O and R)\n",
    "for folder_name in os.listdir(train_data_dir):\n",
    "    folder_path = os.path.join(train_data_dir, folder_name)\n",
    "    \n",
    "    if os.path.isdir(folder_path):\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            \n",
    "            # Check if the file exists\n",
    "            if os.path.isfile(file_path):\n",
    "                # Read and resize the image\n",
    "                image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "                resized_image = cv2.resize(image, image_size)\n",
    "                \n",
    "                train_data.append(resized_image)\n",
    "                train_labels.append(extract_label(folder_name))\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "train_data = np.array(train_data)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "# Iterate through subdirectories (O and R)\n",
    "for folder_name in os.listdir(test_data_dir):\n",
    "    folder_path = os.path.join(test_data_dir, folder_name)\n",
    "    \n",
    "    if os.path.isdir(folder_path):\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            \n",
    "            # Check if the file exists\n",
    "            if os.path.isfile(file_path):\n",
    "                # Read and resize the image\n",
    "                image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "                resized_image = cv2.resize(image, image_size)\n",
    "                \n",
    "                test_data.append(resized_image)\n",
    "                test_labels.append(extract_label(folder_name))\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "test_data = np.array(test_data)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "X_train = train_data\n",
    "y_train = train_labels\n",
    "X_test = test_data\n",
    "y_test = test_labels\n",
    "\n",
    "# Build the CNN model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(image_size[0], image_size[1], 1)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Reshape the data to match the input shape expected by the CNN\n",
    "X_train = X_train.reshape((X_train.shape[0], image_size[0], image_size[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], image_size[0], image_size[1], 1))\n",
    "\n",
    "# Train the model\n",
    "# Define a callback for ModelCheckpoint\n",
    "checkpoint_callback = callbacks.ModelCheckpoint(\n",
    "    filepath='best_model.h5',\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model with the callback\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=500,\n",
    "    batch_size=250,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "accuracy = model.evaluate(X_test, y_test)[1]\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
